{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e29e9b36",
      "metadata": {
        "id": "e29e9b36"
      },
      "source": [
        "# IS 6482 - Week 1 — Exploratory Data Analysis (EDA) + Data Visualization\n",
        "\n",
        "**Author:** Varun Gupta\n",
        "\n",
        "**Agenda:** how to *understand* data before modeling  \n",
        "**Libraries:** `pandas`, `numpy`, `matplotlib`, `seaborn` (optional: `statsmodels` for QQ plots)  \n",
        "**Datasets:** Telco customer churn, Gapminder\n",
        "\n",
        "---\n",
        "\n",
        "### Learning goals\n",
        "By the end of this notebook, you should be able to:\n",
        "\n",
        "1. Quickly inspect a dataset (`.shape`, `.info()`, `.head()`, `.describe()`) and spot obvious issues.\n",
        "2. Summarize distributions (histograms, ECDFs, boxplots) and compare groups.\n",
        "3. Use simple segment analysis to compute and visualize **rates** (e.g., churn rate by segment).\n",
        "4. Explore relationships (correlation, pairplots) to form hypotheses for modeling.\n",
        "5. See a few advanced visualization techniques (reference: [Data Visualization: A Practical Introduction](https://socviz.co/)):  \n",
        "   - bubble plots  \n",
        "   - small multiples (facets)  \n",
        "   - log scales  \n",
        "   - connected dot (dumbbell) comparisons  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d8aac04",
      "metadata": {
        "id": "4d8aac04"
      },
      "source": [
        "## 0. Setup\n",
        "\n",
        "### Takeaways\n",
        "- EDA and Visualization is how we **earn trust** in the dataset and **check our assumption** before we model anything.\n",
        "- We will prefer a small set of libraries you will use repeatedly in business work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f955873",
      "metadata": {
        "id": "1f955873"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Imports and display setup\n",
        "# =========================\n",
        "\n",
        "# Numerical computing (arrays, math helpers)\n",
        "import numpy as np\n",
        "\n",
        "# Tabular data (DataFrames) — the main workhorse for EDA\n",
        "import pandas as pd\n",
        "\n",
        "# Matplotlib = the core plotting library in Python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Seaborn = statistical plotting library built on top of matplotlib\n",
        "import seaborn as sns\n",
        "\n",
        "# Statsmodels for QQ-plot\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Set a consistent visual style (still uses matplotlib underneath)\n",
        "sns.set_theme()\n",
        "'''\n",
        "# Option for prettier output\n",
        "# Jupyter helper: display DataFrames nicely (especially inside loops)\n",
        "from IPython.display import display\n",
        "\n",
        "# Make pandas print wide tables without truncating as aggressively\n",
        "pd.set_option(\"display.max_columns\", 120)\n",
        "pd.set_option(\"display.max_rows\", 200)\n",
        "\n",
        "\n",
        "\n",
        "# Slightly sharper plots in notebooks (purely cosmetic)\n",
        "plt.rcParams[\"figure.dpi\"] = 110\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "760ef42c",
      "metadata": {
        "id": "760ef42c"
      },
      "source": [
        "# Part A — Telco Customer Churn Dataset\n",
        "\n",
        "### The Business problem\n",
        "A common business problem is **customer churn**: “Which customers are likely to leave, why, and how do we retail them?”\n",
        "\n",
        "In this section we will treat **`Churn`** as the outcome/target and practice EDA techniques that will later inform our modeling.\n",
        "\n",
        "### Dataset notes\n",
        "- We will use the “Telco customer churn” dataset originally distributed as an IBM Cognos Analytics sample. It is a synthetic dataset. We will use a subset of the columns -- the full data dictionary is at https://community.ibm.com/community/user/blogs/steven-macko/2019/07/11/telco-customer-churn-1113\n",
        "- For convenience in class, we load a CSV mirror from Plotly’s public datasets repository:  \n",
        "  https://github.com/plotly/datasets/blob/master/telco-customer-churn-by-IBM.csv\n",
        "\n",
        "### Takeaways\n",
        "- Start with a business question and identify the **unit of analysis** (here: one row = one customer).\n",
        "- Identify the **target variable** early (here: `Churn`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f143ca30",
      "metadata": {
        "id": "f143ca30"
      },
      "outputs": [],
      "source": [
        "# ==================================\n",
        "# Load the Telco Customer Churn data\n",
        "# ==================================\n",
        "\n",
        "# The dataset is a CSV file hosted online.\n",
        "# (In a production setting, you'd often load from your company database.)\n",
        "telco_url = \"https://raw.githubusercontent.com/plotly/datasets/master/telco-customer-churn-by-IBM.csv\"\n",
        "\n",
        "# Read the CSV into a pandas DataFrame (a spreadsheet-like table)\n",
        "df = pd.read_csv(telco_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Q7DmJ1t7n6wu",
      "metadata": {
        "id": "Q7DmJ1t7n6wu"
      },
      "outputs": [],
      "source": [
        "# Quick sanity check: how many rows and columns?\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9f943bf",
      "metadata": {
        "id": "a9f943bf"
      },
      "source": [
        "## 1. First look: structure, column names, and data types\n",
        "\n",
        "Sometimes the hardest part of EDA is simply: **“What columns do I have, and how do I grab the rows I want?”**\n",
        "\n",
        "We start with the fastest “risk report” tools:\n",
        "- `.shape` tells us the size of the dataset.\n",
        "- `.head()` / `.tail()` show us what a row looks like.\n",
        "- `.columns` tells you what’s available (the “menu”).\n",
        "- `.info()` reveals data types and missing values.\n",
        "- `.iloc[...]` selects by position (row/column numbers), which is great when you are exploring.\n",
        "\n",
        "### Takeaways\n",
        "- Real datasets often have at least one column with the “wrong” type (e.g., numbers stored as text).\n",
        "- Knowing column names and types early prevents many downstream mistakes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "787b537a",
      "metadata": {
        "id": "787b537a"
      },
      "outputs": [],
      "source": [
        "# First 5 rows: what does one record (one customer) look like?\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "627be19c",
      "metadata": {
        "id": "627be19c"
      },
      "outputs": [],
      "source": [
        "# Last 5 rows: sometimes the bottom of a file reveals parsing issues too\n",
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cc8536c",
      "metadata": {
        "id": "6cc8536c"
      },
      "outputs": [],
      "source": [
        "# List the column names (helpful when you are new to the dataset)\n",
        "df.columns\n",
        "\n",
        "# list(...) prints them as a regular Python list\n",
        "# list(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "657c01b0",
      "metadata": {
        "id": "657c01b0"
      },
      "outputs": [],
      "source": [
        "# .info() is a fast \"risk report\":\n",
        "# - column names\n",
        "# - non-null counts (missing values show up here)\n",
        "# - data types (numeric vs text)\n",
        "df.info()\n",
        "# Seems like we have good news, there seem to be no null entries in this data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c88ae520",
      "metadata": {
        "id": "c88ae520"
      },
      "outputs": [],
      "source": [
        "# .iloc selects by integer position:\n",
        "# - rows 0 to 2 (Python slices exclude the end)\n",
        "# - columns 0 to 5\n",
        "df.iloc[0:3, 0:6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mFgYRrwIsKq9",
      "metadata": {
        "id": "mFgYRrwIsKq9"
      },
      "outputs": [],
      "source": [
        "# .loc selects by index\n",
        "# here 0:2 are the index, and are inclusive unlike list slicing\n",
        "df.loc[0:2, \"customerID\":\"tenure\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5018f922",
      "metadata": {
        "id": "5018f922"
      },
      "source": [
        "### 1.2 Quick summary statistics with `.describe()`\n",
        "\n",
        "`.describe()` gives you a fast summary that helps answer:\n",
        "- “Are values in a reasonable range?”\n",
        "- “Are there obvious outliers?”\n",
        "- “Do we have missing values?”\n",
        "\n",
        "### Takeaways\n",
        "- `.describe()` is a fast way to sanity-check numeric columns.\n",
        "- `.describe(include=\"object\")` pr `df[\"categorical column\"].describe()` summarizes categorical columns (counts, unique values, most common category).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09d07638",
      "metadata": {
        "id": "09d07638"
      },
      "outputs": [],
      "source": [
        "# Numeric summary stats (count, mean, std, min, quartiles, max)\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2BIGZxqtY9H",
      "metadata": {
        "id": "d2BIGZxqtY9H"
      },
      "outputs": [],
      "source": [
        "# Display summary for selected categorical columns\n",
        "df[[\"InternetService\", \"PaymentMethod\"]].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7PhXqvyFI40V",
      "metadata": {
        "id": "7PhXqvyFI40V"
      },
      "outputs": [],
      "source": [
        "# Categorical summary stats for all object columns\n",
        "# Transpose (.T) makes the table easier to read (one row per column)\n",
        "df.describe(include=\"object\").T\n",
        "# Note, there are 11 rows where TotalCharges is empty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qOxljwMEL3h3",
      "metadata": {
        "id": "qOxljwMEL3h3"
      },
      "outputs": [],
      "source": [
        "# A quick histogram plot of the numeric columns using DataFrame.hist() function\n",
        "num_cols = df.select_dtypes(include = 'number').columns\n",
        "df.hist(num_cols);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d27b6af6",
      "metadata": {
        "id": "d27b6af6"
      },
      "source": [
        "### Stop & Discuss (with suggested answers)\n",
        "\n",
        "1) **Question:** In `.info()` and `.describe()`, do you see any columns that *look like numbers but are stored as text*?  \n",
        "\n",
        "2) **Question:** In `.info()` and `.describe()`, do you see any columns that *look like categorical data but are stored as numbers*?  \n",
        "\n",
        "3) **Question:** If a numeric column has a much larger max than the 75th percentile, what might that indicate?  \n",
        "\n",
        "4) **Question:** Why might `.describe()` be misleading for very skewed data?  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20bd7787",
      "metadata": {
        "id": "20bd7787"
      },
      "source": [
        "## 2. Minimal cleaning that EDA almost always discovers\n",
        "\n",
        "Some common issues that should be fixed in EDA:\n",
        "- Identify an ID column (here `customerID` is the correct ID column that identifies rows)\n",
        "- Remove duplicate IDs (if present)\n",
        "- Numeric columns that load as text (often due to blanks)\n",
        "- Convert dtype of categorial attributes from `object` to `category` (efficient for storage and data processing) (*OMITTED TODAY*)\n",
        "- A numeric version of binary target (useful for correlations)\n",
        "\n",
        "### Takeaways\n",
        "- Cleaning is part of EDA, but also guided by EDA: EDA tells you what to clean.\n",
        "- Fixing types early helps your summaries and plots behave correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf20d7d8",
      "metadata": {
        "id": "bf20d7d8"
      },
      "outputs": [],
      "source": [
        "# ==============================\n",
        "# 2. Minimal Data Cleaning\n",
        "# ==============================\n",
        "'''\n",
        "# WE WILL SKIP THIS STEP -- keeping the Id pandas created\n",
        "# ---- Step 1: Identify an ID column (if present) ----\n",
        "# Many real datasets have an ID column like customerID.\n",
        "# We'll look for common names.\n",
        "id_candidates = [\"customerID\", \"CustomerID\", \"customer_id\", \"id\"]\n",
        "\n",
        "id_col = None  # default: we haven't found an ID column yet\n",
        "\n",
        "for candidate in id_candidates:\n",
        "    if candidate in df.columns:\n",
        "        id_col = candidate\n",
        "        break  # stop at the first match\n",
        "\n",
        "if id_col is not None:\n",
        "    # duplicated(...) returns True/False for each row\n",
        "    # sum() counts how many True values we have\n",
        "    duplicate_id_count = df.duplicated(subset=[id_col]).sum()\n",
        "\n",
        "    print(\"ID column detected:\", id_col)\n",
        "    print(\"Duplicate IDs:\", duplicate_id_count)\n",
        "else:\n",
        "    print(\"No obvious ID column found (that's ok for this demo).\")\n",
        "'''\n",
        "# We will drop the customerID column since it will not be useful for us for further analysis\n",
        "# I added the if because sometime we rerun cells, so this avoids getting an error\n",
        "if \"customerID\" in df.columns:\n",
        "    df = df.drop('customerID', axis=1)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oR1TmXibwqDp",
      "metadata": {
        "id": "oR1TmXibwqDp"
      },
      "outputs": [],
      "source": [
        "# ---- Step 2: Fix numeric columns that loaded as text ----\n",
        "# 'TotalCharges' is often stored as an object column because some rows are blank.\n",
        "\n",
        "# pd.to_numeric converts values to floats where possible.\n",
        "# errors=\"coerce\" means: if parsing fails, replace with NaN (missing).\n",
        "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
        "\n",
        "# Confirm that TotalCharges shows up in summary of numerical columns\n",
        "df.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "N_-BkWNuApz0",
      "metadata": {
        "id": "N_-BkWNuApz0"
      },
      "outputs": [],
      "source": [
        "# ---- Step 3: Create a numeric churn flag (0/1) ----\n",
        "# This is convenient later for correlations and simple modeling baselines.\n",
        "\n",
        "# Standardize text: strip spaces and lowercase\n",
        "# df[\"Churn\"].astype(str) returns a data frame with one column (\"Churn\") with entries converted to string\n",
        "# str.strip() returns a copy of the string with leading and trailing whitespaces removed\n",
        "# str.lower() returns the string converted to lower case\n",
        "#churn_clean = df[\"Churn\"].astype(str).str.strip().str.lower()\n",
        "churn_clean = df[\"Churn\"].str.strip().str.lower()\n",
        "\n",
        "# Compare to \"yes\" -> True/False, then convert to 1/0\n",
        "# Create a new column ChurnFlag with this 0/1 data\n",
        "df[\"ChurnFlag\"] = (churn_clean == \"yes\").astype(int)\n",
        "\n",
        "# Confirm that ChurnFlag shows up in summary of numerical columns\n",
        "df.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cN-jzPgiArRp",
      "metadata": {
        "id": "cN-jzPgiArRp"
      },
      "outputs": [],
      "source": [
        "# ---- Step 4: Quick missingness scan ----\n",
        "# isna() gives a True/False DataFrame of missing values.\n",
        "# mean() on True/False gives the fraction missing in each column.\n",
        "# sort_value() will show the columns with most missing fraction on top\n",
        "missing_fraction = df.isna().mean().sort_values(ascending=False)\n",
        "\n",
        "missing_fraction.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4dc2726",
      "metadata": {
        "id": "c4dc2726"
      },
      "source": [
        "## 3. Target variable: class balance and “base rate”\n",
        "\n",
        "Before any model, we want to know:\n",
        "- What fraction of customers churn?\n",
        "- Is the target imbalanced?\n",
        "\n",
        "### Takeaways\n",
        "- The **base rate** answers: “If I predict the majority class every time, how often am I correct?”\n",
        "- Class imbalance affects modeling and evaluation later.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6ecdb55",
      "metadata": {
        "id": "b6ecdb55"
      },
      "outputs": [],
      "source": [
        "# ==============================\n",
        "# 3. Target variable: base rate\n",
        "# ==============================\n",
        "\n",
        "# Count how many customers churned vs not churned\n",
        "# dropna=False keeps missing values (if any) visible in the table\n",
        "churn_counts = df[\"Churn\"].value_counts(dropna=False)\n",
        "\n",
        "churn_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0648bf18",
      "metadata": {
        "id": "0648bf18"
      },
      "outputs": [],
      "source": [
        "# Convert counts to proportions (fractions that sum to 1.0)\n",
        "churn_proportions = df[\"Churn\"].value_counts(normalize=True, dropna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7e5c69c",
      "metadata": {
        "id": "a7e5c69c"
      },
      "outputs": [],
      "source": [
        "# Simple bar chart of churn counts (good for a quick class balance check)\n",
        "plt.figure(figsize=(5, 3))  # (width, height) in inches\n",
        "\n",
        "# value_counts() returns a pandas Series -> Series.plot() uses matplotlib behind the scenes\n",
        "ax = churn_counts.plot(kind=\"bar\")\n",
        "\n",
        "# Add clear labels (always label axes in business work!)\n",
        "ax.set_title(\"Churn counts\")\n",
        "ax.set_xlabel(\"Churn (target)\")\n",
        "ax.set_ylabel(\"Number of customers\")\n",
        "\n",
        "plt.tight_layout()  # reduces label cutoff\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98ffafcf",
      "metadata": {
        "id": "98ffafcf"
      },
      "source": [
        "### Stop & Discuss: what does class balance imply?\n",
        "\n",
        "1) **Question:** If we always predict the most common class (usually “No churn”), why can the accuracy look “good” even if the model is useless?  \n",
        "\n",
        "2) **Question:** In a churn context, which is usually more costly: a false positive (predict churn but they stay) or a false negative (predict stay but they churn)?  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb2cb0c2",
      "metadata": {
        "id": "cb2cb0c2"
      },
      "source": [
        "## 4. Categorical EDA: what are the big segments?\n",
        "\n",
        "For categorical columns, we often start with:\n",
        "- `.value_counts()` (counts and proportions; returns the counts in descending order)\n",
        "- bar charts (sorted)\n",
        "\n",
        "### Takeaways\n",
        "- Segment size matters: a segment can have high churn rate but be tiny.\n",
        "- EDA is partly about **prioritization**: focus on columns that are likely to matter for business decisions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c47d6b1a",
      "metadata": {
        "id": "c47d6b1a"
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# 4. Categorical EDA: what are the big segments?\n",
        "# ============================================\n",
        "\n",
        "# In pandas, categorical columns are often stored as dtype \"object\" (text).\n",
        "# We also want to exclude the ID and target columns from the \"feature\" list.\n",
        "exclude_cols = []\n",
        "\n",
        "exclude_cols.append(\"Churn\")\n",
        "exclude_cols.append(\"ChurnFlag\")\n",
        "\n",
        "# Build a list of categorical feature columns (with type object)\n",
        "cat_cols = []\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == \"object\" and col not in exclude_cols:\n",
        "        cat_cols.append(col)\n",
        "\n",
        "cat_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0db1530",
      "metadata": {
        "id": "d0db1530"
      },
      "outputs": [],
      "source": [
        "# Show frequency tables for a few business-relevant categorical columns\n",
        "key_cats = [\"Contract\", \"InternetService\", \"PaymentMethod\", \"PaperlessBilling\", \"gender\"]\n",
        "\n",
        "for col in key_cats:\n",
        "    print(\"\\n\" + \"=\" * 90)\n",
        "    print(\"Column:\", col)\n",
        "\n",
        "    # Counts: how many rows in each category?\n",
        "    counts = df[col].value_counts(dropna=False)\n",
        "\n",
        "    # Proportions: what fraction of customers are in each category?\n",
        "    proportions = df[col].value_counts(normalize=True, dropna=False)\n",
        "\n",
        "    # Combine into a single easy-to-read table\n",
        "    summary_table = pd.DataFrame({\n",
        "        \"count\": counts,\n",
        "        \"proportion\": proportions\n",
        "    })\n",
        "\n",
        "    display(summary_table.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d0ca090",
      "metadata": {
        "id": "0d0ca090"
      },
      "outputs": [],
      "source": [
        "# A readable bar chart for one important categorical variable (Contract)\n",
        "plt.figure(figsize=(7, 3))\n",
        "\n",
        "# Order bars from most common to least common\n",
        "order = df[\"Contract\"].value_counts().index\n",
        "\n",
        "# countplot shows category counts; order= controls the category order\n",
        "sns.countplot(data=df, x=\"Contract\", order=order)\n",
        "\n",
        "plt.title(\"Contract type distribution\")\n",
        "plt.xlabel(\"Contract\")\n",
        "plt.ylabel(\"Number of customers\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4b77d86",
      "metadata": {
        "id": "b4b77d86"
      },
      "outputs": [],
      "source": [
        "# Find Churn Rate within each segment of Contract\n",
        "churn_by_contract = df[\"ChurnFlag\"].groupby(df[\"Contract\"]).mean()\n",
        "\n",
        "#Sort for readability\n",
        "churn_by_contract = churn_by_contract.sort_values(ascending=True)\n",
        "\n",
        "display(churn_by_contract)\n",
        "\n",
        "# 4) Plot (horizontal bar chart is readable for long labels)\n",
        "plt.figure(figsize=(8, 3))\n",
        "churn_by_contract.mul(100).plot(kind=\"bar\")  # multiply by 100 to show percent, barh for horizontal bars\n",
        "plt.xlabel(\"Churn rate (%)\")\n",
        "plt.ylabel(\"Payment method\")\n",
        "plt.title(\"Churn rate by PaymentMethod (sorted)\");"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2875a075",
      "metadata": {
        "id": "2875a075"
      },
      "source": [
        "### Stop & Discuss: segments vs outcomes\n",
        "\n",
        "1) **Question:** Why do we look at segment size *and* churn rate?  \n",
        "\n",
        "2) **Question:** If one segment has high churn, does that prove the segment *causes* churn?  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "428e24f9",
      "metadata": {
        "id": "428e24f9"
      },
      "source": [
        "## 5. Numeric distributions (univariate): histograms, ECDFs, boxplots, normal overlay, QQ plot\n",
        "\n",
        "We will practice multiple ways to look at *one* numeric column:\n",
        "- Histogram: fast shape check (but depends on bins)\n",
        "- ECDF: distribution view without bins\n",
        "- Boxplot: median + spread + outliers\n",
        "- Normal overlay + QQ plot: check whether “normality” is a reasonable approximation\n",
        "\n",
        "### Takeaways\n",
        "- Different plots show different things\n",
        "- Many business variables are **not** normally distributed; checking is easy and worth it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2ffd042",
      "metadata": {
        "id": "a2ffd042"
      },
      "outputs": [],
      "source": [
        "# Identify numeric columns (numbers we can compute means/correlations on)\n",
        "num_cols = df.select_dtypes(include=\"number\").columns.tolist()\n",
        "\n",
        "num_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7710dc3e",
      "metadata": {
        "id": "7710dc3e"
      },
      "outputs": [],
      "source": [
        "# Quick histogram grid for numeric columns\n",
        "# - bins controls how many bars we use\n",
        "# - figsize controls overall plot size\n",
        "df[num_cols].hist(bins=30, figsize=(12, 8))\n",
        "plt.suptitle(\"Numeric distributions (histograms)\");"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f803729",
      "metadata": {
        "id": "8f803729"
      },
      "source": [
        "### Stop & Discuss: reading histograms\n",
        "\n",
        "1) **Question:** Which numeric variables look skewed or have long tails?  \n",
        "   \n",
        "2) **Question:** If you see a spike at 0 (or a strange gap), what might that mean?  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8c65777",
      "metadata": {
        "id": "a8c65777"
      },
      "source": [
        "### 5.1 ECDF (Empirical CDF)\n",
        "\n",
        "ECDF answers: “What fraction of customers are below this value?”\n",
        "\n",
        "**Why it’s nice:** it avoids arguments about histogram bin sizes.\n",
        "\n",
        "(Seaborn ECDF docs: https://seaborn.pydata.org/generated/seaborn.ecdfplot.html)\n",
        "\n",
        "### Takeaways\n",
        "- ECDF is often easier than histograms for comparing groups.\n",
        "- When curves differ a lot, the groups differ a lot.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd7e0638",
      "metadata": {
        "id": "dd7e0638"
      },
      "outputs": [],
      "source": [
        "# ECDF for MonthlyCharges (or fall back to the first numeric column)\n",
        "# ECDF = Empirical Cumulative Distribution Function:\n",
        "# it shows the fraction of observations <= a given value.\n",
        "\n",
        "col = \"MonthlyCharges\"\n",
        "\n",
        "plt.figure(figsize=(7, 4))\n",
        "\n",
        "sns.ecdfplot(data=df, x=col, hue=\"Churn\")\n",
        "plt.grid(True)\n",
        "plt.title(f\"ECDF of {col}\")\n",
        "plt.xlabel(col)\n",
        "plt.ylabel(\"Proportion of customers ≤ x\");"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6e5c0d2",
      "metadata": {
        "id": "d6e5c0d2"
      },
      "source": [
        "### Stop & Discuss: how to read an ECDF\n",
        "\n",
        "1) **Question:** At a value *x* on the horizontal axis, what does the ECDF’s y-value mean?  \n",
        "   \n",
        "2) **Question:** When comparing two ECDF lines (Churn=Yes vs No), what does it mean if one line is consistently above the other?  \n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d2fe6fa",
      "metadata": {
        "id": "9d2fe6fa"
      },
      "source": [
        "### 5.2 Boxplots (including group comparison)\n",
        "\n",
        "Boxplots help spot outliers and compare churn vs non-churn quickly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a451439",
      "metadata": {
        "id": "3a451439"
      },
      "outputs": [],
      "source": [
        "# Boxplots show:\n",
        "# - median (line)\n",
        "# - middle 50% range (box)\n",
        "# - potential outliers (points beyond whiskers)\n",
        "col = \"MonthlyCharges\"\n",
        "\n",
        "# ---- Boxplot for the full dataset ----\n",
        "plt.figure(figsize=(6, 3))\n",
        "plt.boxplot(df[col].dropna())\n",
        "plt.title(f\"Boxplot of {col}\")\n",
        "plt.ylabel(col)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c99x5t9wYhBm",
      "metadata": {
        "id": "c99x5t9wYhBm"
      },
      "outputs": [],
      "source": [
        "# ---- Boxplot split by churn group ----\n",
        "plt.figure(figsize=(6, 3))\n",
        "sns.boxplot(data=df, x=\"Churn\", y=col)\n",
        "plt.title(f\"{col} by churn\")\n",
        "plt.xlabel(\"Churn\")\n",
        "plt.ylabel(col)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0aeb614",
      "metadata": {
        "id": "e0aeb614"
      },
      "source": [
        "### 5.3 Histogram + Normal overlay (reference only)\n",
        "\n",
        "We sometimes compare a distribution to a normal curve as a quick sanity check.\n",
        "This is *not* a test — it’s a visual reference.\n",
        "\n",
        "### Takeaways\n",
        "- If the data is highly skewed or heavy-tailed, normal assumptions may break.\n",
        "- The goal is awareness, not perfection.\n",
        "- Sometimes this can help us realize that we need to **transform** the data before further analysis (example, log transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca4a791a",
      "metadata": {
        "id": "ca4a791a"
      },
      "outputs": [],
      "source": [
        "# Histogram vs. Normal overlay\n",
        "# Goal: visually compare a real business variable to a \"perfect normal\" distribution.\n",
        "# This is useful because many modeling methods assume (approximately) normal errors.\n",
        "\n",
        "col = \"MonthlyCharges\"\n",
        "\n",
        "# Drop missing values and ensure the data is float\n",
        "x = df[col].dropna()\n",
        "\n",
        "# Compute mean and sample standard deviation (ddof=1 = sample std)\n",
        "mu = x.mean()\n",
        "sigma = x.std()\n",
        "\n",
        "# Build a smooth x-axis for the normal curve\n",
        "xs = np.linspace(x.min(), x.max(), 100)\n",
        "\n",
        "# Normal distribution PDF formula (so we don't need extra libraries)\n",
        "pdf = (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((xs - mu) / sigma) ** 2)\n",
        "\n",
        "plt.figure(figsize=(7, 4))\n",
        "\n",
        "# density=True scales the histogram so the area sums to 1 (so we can overlay a PDF)\n",
        "plt.hist(x, bins=30, density=True, alpha=0.6, label=\"Data (histogram)\")\n",
        "\n",
        "# Plot the normal curve with the same mean/std\n",
        "plt.plot(xs, pdf, label=\"Normal curve (same mean/std)\")\n",
        "\n",
        "plt.title(f\"{col}: histogram (density) + normal overlay\")\n",
        "plt.xlabel(col)\n",
        "plt.ylabel(\"Density\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Column Mean = {mu:.2f}, Column Std = {sigma:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1UE_1yFugtos",
      "metadata": {
        "id": "1UE_1yFugtos"
      },
      "outputs": [],
      "source": [
        "# ECDF vs. Normal Overlay\n",
        "import seaborn as sns\n",
        "from scipy.stats import norm\n",
        "\n",
        "col = \"MonthlyCharges\"\n",
        "\n",
        "# Drop missing values and ensure the data is float\n",
        "x = df[col].dropna()\n",
        "# Compute mean and sample standard deviation (ddof=1 = sample std)\n",
        "mu = x.mean()\n",
        "sigma = x.std()\n",
        "# Build a smooth x-axis for the normal curve\n",
        "xs = np.linspace(x.min(), x.max(), 100)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.ecdfplot(data = df, x = x, label = 'Data (ECDF)')\n",
        "# Calculate the theoretical CDF for these x values\n",
        "# using the mean and std dev of your generated data (or known population parameters)\n",
        "ys = norm.cdf(xs, mu, sigma)\n",
        "plt.plot(xs, ys, color='red', linestyle='--', label='Theoretical Normal CDF');\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8e50498",
      "metadata": {
        "id": "f8e50498"
      },
      "source": [
        "### 5.4 QQ / Probability plot (optional but powerful)\n",
        "\n",
        "A QQ/probability plot compares your sample quantiles to theoretical normal quantiles.\n",
        "\n",
        "- If points follow the line closely → normal approximation might be reasonable.\n",
        "- Curvature (especially at the ends) → non-normal tails/skew.\n",
        "\n",
        "(SciPy probplot docs: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.probplot.html)\n",
        "\n",
        "### Takeaways\n",
        "- QQ plots show *where* the distribution differs (often in the tails).\n",
        "- Tails matter in business (risk, churn extremes, high-spend customers)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15735275",
      "metadata": {
        "id": "15735275"
      },
      "outputs": [],
      "source": [
        "# QQ / Probability plot (optional but powerful)\n",
        "# If statsmodels is available, api.qqplot gives a fast diagnostic against a theoretical distribution.\n",
        "\n",
        "col = \"MonthlyCharges\"\n",
        "# Drop missing values and ensure the data is float\n",
        "x = df[col].dropna()\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "# dist=\"norm\" means: compare against the normal distribution\n",
        "sm.qqplot(x, line='s')\n",
        "plt.title(f\"QQ-plot (normal) for {col}\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e02fad2c",
      "metadata": {
        "id": "e02fad2c"
      },
      "source": [
        "## 6. Compare churn vs non-churn (tables + plots)\n",
        "\n",
        "A simple, powerful pattern:\n",
        "1. Group by the target (`Churn`)\n",
        "2. Summarize numeric columns (`.describe()`, quantiles)\n",
        "3. Visualize differences (boxplots, ECDF by group)\n",
        "\n",
        "### Takeaways\n",
        "- Tables give **effect size** (how big the difference is).\n",
        "- We are not “modeling” yet: we are building intuition and hypotheses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cb5b03e",
      "metadata": {
        "id": "0cb5b03e"
      },
      "outputs": [],
      "source": [
        "# ==============================================\n",
        "# 6. Compare churn vs non-churn (tables + plots)\n",
        "# ==============================================\n",
        "\n",
        "# Pick a small set of numeric columns that are meaningful in this dataset\n",
        "numeric_focus = [\"tenure\", \"MonthlyCharges\", \"TotalCharges\"]\n",
        "\n",
        "# groupby(\"Churn\") splits rows into two groups (Yes/No)\n",
        "# describe() computes count/mean/std/min/quantiles/max for each numeric column\n",
        "summary = df.groupby(\"Churn\")[numeric_focus].describe().T\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "summary"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8e43097",
      "metadata": {
        "id": "b8e43097"
      },
      "source": [
        "## 7. Segment analysis: churn-rate heatmap (graph-table style)\n",
        "\n",
        "Instead of asking “How many churned?” we ask:\n",
        "> “What is the **churn rate** among customers with Contract = \"One Year\" and InternetService = \"DSL\"?\n",
        "\n",
        "A useful pattern:\n",
        "- Use `pd.crosstab(..., aggfunc=\"mean\")` on a boolean churn indicator (crosstab = crosstabulation)\n",
        "- Visualize it as a heatmap\n",
        "\n",
        "### Takeaways\n",
        "- Rates are usually more actionable than raw counts.\n",
        "- Segment heatmaps are close to what many business dashboards need.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b9ecce5",
      "metadata": {
        "id": "2b9ecce5"
      },
      "outputs": [],
      "source": [
        "# =========================================================\n",
        "# 7. Segment analysis: churn-rate heatmap (graph-table style)\n",
        "# =========================================================\n",
        "# We want churn RATE (a percentage), not just churn counts.\n",
        "# A good segment plot answers: \"Which groups have the highest churn rate?\"\n",
        "\n",
        "# Pick two segmentation columns if present\n",
        "row_col = \"Contract\"\n",
        "col_col = \"InternetService\"\n",
        "\n",
        "# Crosstab + aggfunc=\"mean\":\n",
        "# mean(True/False) = fraction True = churn rate\n",
        "churn_rate = pd.crosstab(\n",
        "        df[row_col],               # rows\n",
        "        df[col_col],               # columns\n",
        "        values=df['ChurnFlag'],         # values to aggregate\n",
        "        aggfunc=\"mean\"             # mean -> rate\n",
        "    )\n",
        "\n",
        "display(churn_rate)\n",
        "\n",
        "plt.figure(figsize=(7, 4))\n",
        "\n",
        "# annot = True prints the values inside cells\n",
        "# fmt = \".1%\" formats as a percentage with 1 decimal place\n",
        "sns.heatmap(churn_rate, annot=True, fmt=\".1%\")\n",
        "\n",
        "plt.title(\"Churn rate by segment\")\n",
        "plt.ylabel(row_col)\n",
        "plt.xlabel(col_col)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8902ad7",
      "metadata": {
        "id": "b8902ad7"
      },
      "source": [
        "### Stop & Discuss: interpreting the churn-rate heatmap\n",
        "\n",
        "1) **Question:** Which segment combination has the highest churn rate?  \n",
        "\n",
        "2) **Question:** If a segment has high churn, what are two *non-causal* explanations you should consider?  \n",
        "\n",
        "3) **Question:** What additional slice would you look at next to refine the story?  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9264372",
      "metadata": {
        "id": "b9264372"
      },
      "source": [
        "## 8. Correlations (numeric) + heatmap\n",
        "\n",
        "Correlation is a screening tool:\n",
        "- Good for fast detection of linear relationships\n",
        "- Not evidence of causality\n",
        "\n",
        "### Takeaways\n",
        "- Correlation helps you ask better questions.\n",
        "- Correlation ≠ causation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ec6b2d8",
      "metadata": {
        "id": "8ec6b2d8"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 8. Correlations (numeric subset) + heatmap\n",
        "# ==========================================\n",
        "\n",
        "# Correlation measures *linear* relationship between two numeric variables.\n",
        "# We'll focus on a small numeric set plus ChurnFlag (0/1).\n",
        "numeric_focus = [\"tenure\", \"MonthlyCharges\", \"TotalCharges\", \"ChurnFlag\"]\n",
        "\n",
        "# corr() returns a correlation matrix (table)\n",
        "corr = df[numeric_focus].corr(numeric_only=True)\n",
        "\n",
        "corr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "256bd83f",
      "metadata": {
        "id": "256bd83f"
      },
      "outputs": [],
      "source": [
        "# Visualize the correlation matrix as a heatmap\n",
        "plt.figure(figsize=(6, 4))\n",
        "\n",
        "# center=0 makes 0 correlation a neutral color (helps interpretation)\n",
        "sns.heatmap(corr, annot=True, center=0)\n",
        "\n",
        "plt.title(\"Correlation heatmap (numeric subset)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24e2c59a",
      "metadata": {
        "id": "24e2c59a"
      },
      "source": [
        "### Stop & Discuss: what correlation is (and isn’t)\n",
        "\n",
        "1) **Question:** What does a correlation of +0.7 mean in plain language?  \n",
        "   \n",
        "2) **Question:** Why might correlation miss an important relationship?  \n",
        "   \n",
        "3) **Question:** Why does correlating with `ChurnFlag` (0/1) sometimes still make sense?  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35fe3189",
      "metadata": {
        "id": "35fe3189"
      },
      "source": [
        "## 9. Pairplot (curated variables + engineered ServiceCount)\n",
        "\n",
        "Pairplots help us see:\n",
        "- clusters\n",
        "- separation between churn vs non-churn\n",
        "- non-linear relationships\n",
        "\n",
        "But pairplots do **not** scale to dozens of variables. We keep it small and readable.\n",
        "\n",
        "### Takeaways\n",
        "- Pairplots are best for a curated subset (3–6 variables).\n",
        "- Light feature engineering can reveal structure that raw columns hide.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0a12f4b",
      "metadata": {
        "id": "e0a12f4b"
      },
      "outputs": [],
      "source": [
        "# ==========================================================\n",
        "# 10. Pairplot (curated variables + engineered ServiceCount)\n",
        "# ==========================================================\n",
        "\n",
        "# Many telco columns are Yes/No service flags. Let's create one simple summary:\n",
        "# ServiceCount = how many optional services the customer has.\n",
        "\n",
        "services = [\n",
        "    \"OnlineSecurity\",\n",
        "    \"OnlineBackup\",\n",
        "    \"DeviceProtection\",\n",
        "    \"TechSupport\",\n",
        "    \"StreamingTV\",\n",
        "    \"StreamingMovies\",\n",
        "    \"MultipleLines\",\n",
        "]\n",
        "\n",
        "df[\"ServiceCount\"] = 0  # start at 0 for everyone\n",
        "\n",
        "for col in services:\n",
        "    # Add 1 if the service is \"Yes\", else add 0\n",
        "    df[\"ServiceCount\"] += df[col].astype(str).str.strip().eq(\"Yes\").astype(int)\n",
        "\n",
        "df[\"ServiceCount\"].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f6949ea",
      "metadata": {
        "id": "6f6949ea"
      },
      "outputs": [],
      "source": [
        "# Select a small set of numeric columns for the pairplot (readable, not overwhelming)\n",
        "pair_cols =  [\"tenure\", \"MonthlyCharges\", \"TotalCharges\", \"ServiceCount\"]\n",
        "\n",
        "# Pairplot can be slow for large datasets. We'll sample to keep it fast in class.\n",
        "# Fix: Use a single list to select all required columns including the hue variable\n",
        "pair_df = df[pair_cols + [\"ChurnFlag\"]].dropna()\n",
        "\n",
        "# Sample down to at most 1000 rows for less cluttered plot (adjust as needed)\n",
        "if len(pair_df) > 1000:\n",
        "    pair_df = pair_df.sample(1000, random_state=42)\n",
        "\n",
        "# pairplot shows:\n",
        "# - scatterplots for each pair of variables\n",
        "# - KDEs on the diagonal (diag_kind=\"kde\")\n",
        "# - hue=\"ChurnFlag\" colors points by churn group\n",
        "g = sns.pairplot(\n",
        "    data=pair_df,\n",
        "    vars=pair_cols,\n",
        "    hue=\"ChurnFlag\",\n",
        "    diag_kind=\"kde\",\n",
        "    corner=True,                 # only plot the lower triangle (less clutter)\n",
        "    plot_kws={\"alpha\": 0.4, \"s\": 18}  # alpha = transparency, s = marker size\n",
        ")\n",
        "\n",
        "g.fig.suptitle(\"Pairplot (sampled) — look for separation and relationships\", y=1.02)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3iMCdWW9hqRx",
      "metadata": {
        "id": "3iMCdWW9hqRx"
      },
      "outputs": [],
      "source": [
        "# sns.pairplot(df, vars=pair_cols, kind = 'reg');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xeGDjDw8h3sr",
      "metadata": {
        "id": "xeGDjDw8h3sr"
      },
      "outputs": [],
      "source": [
        "# sns.pairplot(df, vars=pair_cols, hue = 'Churn', palette = 'husl', markers = ['o', 'D']);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a81d9bc",
      "metadata": {
        "id": "9a81d9bc"
      },
      "source": [
        "### Stop & Discuss: what story does the pairplot tell?\n",
        "\n",
        "1) **Question:** Do churners and non-churners look separated in any pair of variables?  \n",
        "\n",
        "2) **Question:** If there is no clear visual separation, does that mean churn is not predictable?  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6e17cb7",
      "metadata": {
        "id": "f6e17cb7"
      },
      "source": [
        "## 10. Telco recap: a reusable EDA checklist\n",
        "\n",
        "### A practical EDA checklist\n",
        "1. Define the business question + unit of analysis (row = what?)\n",
        "2. Inspect structure (`.shape`, `.head()`, `.info()`)\n",
        "3. Fix obvious issues (types, missingness, duplicates)\n",
        "4. Understand the target (base rate / class balance)\n",
        "5. Summarize categorical columns (`value_counts`)\n",
        "6. Summarize numeric columns (`describe`, hist/ECDF/boxplot)\n",
        "7. Compare target groups (groupby summaries + plots)\n",
        "8. Segment analysis (rates, heatmaps)\n",
        "9. Relationship scan (correlation, pairplot)\n",
        "10. Write down 3–5 hypotheses to test with models\n",
        "\n",
        "### Takeaways\n",
        "- EDA is a repeatable workflow, not a mystery.\n",
        "- The goal is not “make lots of plots.” The goal is to decide what to do next.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bae02af3",
      "metadata": {
        "id": "bae02af3"
      },
      "source": [
        "# Part B — Visualization Studio Add-on (Gapminder)  \n",
        "*(Still only matplotlib + seaborn)*\n",
        "\n",
        "Now we’ll switch domains and focus on visualization patterns you can reuse:\n",
        "- log scales for skewed variables\n",
        "- small multiples (facets)\n",
        "- connected dot (dumbbell) comparisons\n",
        "\n",
        "### Dataset notes\n",
        "- Gapminder provides data as downloadable CSV indicators: https://www.gapminder.org/data/\n",
        "- We load a common “five-year” Gapminder CSV from Plotly’s datasets repository:  \n",
        "  https://github.com/plotly/datasets/blob/master/gapminderDataFiveYear.csv\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08aa2027",
      "metadata": {
        "id": "08aa2027"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# Load Gapminder data (CSV) with pandas\n",
        "# ==========================================\n",
        "\n",
        "gap_url = \"https://raw.githubusercontent.com/plotly/datasets/master/gapminderDataFiveYear.csv\"\n",
        "\n",
        "# Read into a DataFrame\n",
        "gap = pd.read_csv(gap_url)\n",
        "\n",
        "# Quick shape check\n",
        "gap.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5d4fe76",
      "metadata": {
        "id": "b5d4fe76"
      },
      "outputs": [],
      "source": [
        "# First few rows: what columns do we have?\n",
        "gap.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf1ac94c",
      "metadata": {
        "id": "cf1ac94c"
      },
      "outputs": [],
      "source": [
        "# Column types + missingness\n",
        "gap.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "665d63bf",
      "metadata": {
        "id": "665d63bf"
      },
      "source": [
        "## 11. Bubble scatter (2007 snapshot): life expectancy vs GDP per capita (log x-axis)\n",
        "\n",
        "We’ll replicate a classic view:\n",
        "- `x = gdpPercap` (log scale)\n",
        "- `y = lifeExp`\n",
        "- `size = pop`\n",
        "- `hue = continent`\n",
        "\n",
        "### Takeaways\n",
        "- Log scales can reveal relationships hidden by skewed axes.\n",
        "- Multi-encoding (x/y/color/size) is powerful, but readability matters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "922a80fe",
      "metadata": {
        "id": "922a80fe"
      },
      "outputs": [],
      "source": [
        "# -----------------------------------------\n",
        "# Bubble scatter (2007 snapshot)\n",
        "# -----------------------------------------\n",
        "# x = GDP per capita (log scale)\n",
        "# y = life expectancy\n",
        "# size = population\n",
        "# color = continent\n",
        "\n",
        "# Filter to one year (keeps the plot readable)\n",
        "gap07 = gap.query(\"year == 2007\").copy()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "ax = sns.scatterplot(\n",
        "    data=gap07,\n",
        "    x=\"gdpPercap\",\n",
        "    y=\"lifeExp\",\n",
        "    hue=\"continent\",\n",
        "    size=\"pop\",\n",
        "    sizes=(20, 1200),   # min and max marker sizes\n",
        "    alpha=0.7\n",
        ")\n",
        "\n",
        "# GDP per capita is very skewed; log scale makes patterns easier to see\n",
        "# ax.set_xscale(\"log\")\n",
        "\n",
        "ax.set_title(\"2007: Life expectancy vs GDP per capita (log scale)\")\n",
        "ax.set_xlabel(\"GDP per capita (log scale)\")\n",
        "ax.set_ylabel(\"Life expectancy\")\n",
        "\n",
        "# Move legend outside the plot so it doesn't cover points\n",
        "plt.legend(bbox_to_anchor=(1.02, 1), loc=\"upper left\", title=\"Continent\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56076511",
      "metadata": {
        "id": "56076511"
      },
      "source": [
        "### Stop & Discuss: what story does the bubble chart tell?\n",
        "\n",
        "1) **Question:** What is the overall relationship between GDP per capita and life expectancy?  \n",
        "\n",
        "2) **Question:** Why do we use a log scale for GDP per capita?  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2169afb2",
      "metadata": {
        "id": "2169afb2"
      },
      "source": [
        "## 11. Small multiples (facets): same scatter, split by continent\n",
        "\n",
        "Small multiples reduce clutter and make comparisons easier.\n",
        "\n",
        "### Takeaways\n",
        "- If one plot is too busy, don’t fight it — **split it**.\n",
        "- Facets make patterns visible without needing a complicated legend.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb508c48",
      "metadata": {
        "id": "cb508c48"
      },
      "outputs": [],
      "source": [
        "# -----------------------------------------\n",
        "# Small multiples (FacetGrid) by continent\n",
        "# -----------------------------------------\n",
        "# This reduces clutter and makes continent-by-continent comparisons easier.\n",
        "\n",
        "g = sns.FacetGrid(\n",
        "    data=gap07,\n",
        "    col=\"continent\",\n",
        "    col_wrap=3,     # wrap into multiple rows\n",
        "    height=3,\n",
        "    sharex=False,   # allow each facet to choose its own x-limits\n",
        "    sharey=True\n",
        ")\n",
        "\n",
        "# Draw the same plot in each facet\n",
        "g.map_dataframe(sns.scatterplot, x=\"gdpPercap\", y=\"lifeExp\", alpha=0.7)\n",
        "\n",
        "# Apply log scale to each facet axis\n",
        "for ax in g.axes.flatten():\n",
        "    ax.set_xscale(\"log\")\n",
        "\n",
        "g.set_axis_labels(\"GDP per capita (log scale)\", \"Life expectancy\")\n",
        "g.fig.suptitle(\"2007: LifeExp vs GDP per capita by continent\", y=1.02)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "395e583d",
      "metadata": {
        "id": "395e583d"
      },
      "source": [
        "### Stop & Discuss: why small multiples?\n",
        "\n",
        "1) **Question:** What do you see in the faceted plots that was harder to see in the single global plot?  \n",
        "\n",
        "2) **Question:** When is faceting a bad idea?  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62adf35a",
      "metadata": {
        "id": "62adf35a"
      },
      "source": [
        "## 12. Dumbbell (connected dot) plot: life expectancy change from 1952 → 2007\n",
        "\n",
        "A dumbbell plot is great for comparing two time points across categories (here: countries).\n",
        "It is also called a “connected dot plot.”  \n",
        "Examples/definitions:  \n",
        "- https://datavizcatalogue.com/blog/chart-snapshot-dumbbell-plot/  \n",
        "- https://datavizproject.com/data-type/dumbbell-plot/\n",
        "\n",
        "We will:\n",
        "1. Choose the top 10 countries by population in 2007\n",
        "2. Compare life expectancy in 1952 vs 2007\n",
        "\n",
        "### Takeaways\n",
        "- For “before vs after,” a dumbbell plot is often clearer than many time series lines.\n",
        "- The connecting line makes *difference* the visual focus.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29f4acf5",
      "metadata": {
        "id": "29f4acf5"
      },
      "outputs": [],
      "source": [
        "# -----------------------------------------\n",
        "# Dumbbell / connected dot plot (1952 -> 2007)\n",
        "# -----------------------------------------\n",
        "# A dumbbell plot is great for \"before vs after\" comparisons.\n",
        "\n",
        "# Pick a set of countries: top 10 by population in 2007\n",
        "top_countries = gap07.nlargest(10, \"pop\")[\"country\"].tolist()\n",
        "\n",
        "# Keep only those countries and the two years we care about\n",
        "subset = gap[\n",
        "    gap[\"country\"].isin(top_countries) &\n",
        "    gap[\"year\"].isin([1952, 2007])\n",
        "].copy()\n",
        "\n",
        "# Pivot so we get one row per country and two columns: 1952 and 2007\n",
        "pivot = subset.pivot(index=\"country\", columns=\"year\", values=\"lifeExp\")\n",
        "\n",
        "# Add an improvement column to sort countries by change\n",
        "pivot[\"improvement\"] = pivot[2007] - pivot[1952]\n",
        "\n",
        "# Sort so the biggest improvers appear at the top of the plot\n",
        "pivot = pivot.sort_values(\"improvement\")\n",
        "\n",
        "pivot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "583a6d8a",
      "metadata": {
        "id": "583a6d8a"
      },
      "outputs": [],
      "source": [
        "# Plot the dumbbell chart (life expectancy in 1952 vs 2007)\n",
        "y_positions = np.arange(len(pivot))  # 0..N-1\n",
        "\n",
        "plt.figure(figsize=(9, 6))\n",
        "\n",
        "# Horizontal lines connect 1952 to 2007 for each country\n",
        "plt.hlines(\n",
        "    y=y_positions,\n",
        "    xmin=pivot[1952],\n",
        "    xmax=pivot[2007]\n",
        ")\n",
        "\n",
        "# Points for each year\n",
        "plt.plot(pivot[1952], y_positions, \"o\", label=\"1952\")\n",
        "plt.plot(pivot[2007], y_positions, \"o\", label=\"2007\")\n",
        "\n",
        "# Label y-axis with country names\n",
        "plt.yticks(y_positions, pivot.index)\n",
        "\n",
        "plt.title(\"Life expectancy change (1952 → 2007) for top-population countries\")\n",
        "plt.xlabel(\"Life expectancy (years)\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aab315ed",
      "metadata": {
        "id": "aab315ed"
      },
      "source": [
        "### Stop & Discuss: interpreting the dumbbell plot\n",
        "\n",
        "1) **Question:** Which country improved the most in life expectancy (1952 → 2007) *within this selected set*?  \n",
        "\n",
        "2) **Question:** Why might we prefer a dumbbell plot over plotting a full time series for 10 countries?  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56c2b3d8",
      "metadata": {
        "id": "56c2b3d8"
      },
      "source": [
        "# Wrap-up and quick practice\n",
        "\n",
        "### What you practiced today\n",
        "- Inspecting structure and types (`info`, `describe`, missingness)\n",
        "- Distribution views (hist, ECDF, boxplot, normal overlay, QQ plot)\n",
        "- Group comparisons (`groupby().describe()`)\n",
        "- Segment churn rates with heatmaps (graph-table style)\n",
        "- Relationship scans (correlation, encoded correlations, pairplots)\n",
        "- Visualization patterns (log scale, facets, dumbbell comparison)\n",
        "\n",
        "### Practice exercises\n",
        "1. **Telco:**  Which payment methods have the highest churn rate?\n",
        "2. **Gapminder:** Which country improved its life expectancy the most?\n",
        "\n",
        "### Takeaways\n",
        "- EDA is a workflow you can reuse in every project.\n",
        "- The best plots make the next decision obvious."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
