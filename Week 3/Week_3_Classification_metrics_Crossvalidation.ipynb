{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2c55aa38",
      "metadata": {
        "id": "2c55aa38"
      },
      "source": [
        "# IS 6482 - Week 3 — Classification Metrics and Cross-Validation\n",
        "\n",
        "**Author:** Varun Gupta\n",
        "\n",
        "**Agenda:** Confusion Matrix, Classification Metrics, ROC Curve, Cross-Validation  \n",
        "\n",
        "**Libraries:** `sklearn.tree`, `sklearn.metrics`, `sklearn.model_selection`\n",
        "\n",
        "**Datasets:** Telco customer churn\n",
        "\n",
        "---\n",
        "\n",
        "### Learning goals\n",
        "By the end of this notebook, you should be able to:\n",
        "\n",
        "1. Learn how to create **train/test splits** to create a hold out set for model evaluation\n",
        "2. Produce **confusion matrix** and metrics like **Precision**, **Recall**, **F-score**\n",
        "3. Report **ROC curve** and **AUC** by using Decision Tree as a probabilistic classifier\n",
        "4. Use **cross-validation** for model selection (in the case of Decision Tree this would be number of leaves, or pruning parameter)\n",
        "\n",
        "**Dataset**: Telco Customer Churn (IBM sample) mirrored as a CSV in a public repo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffd8d6fa",
      "metadata": {
        "id": "ffd8d6fa"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 0) Imports + plotting defaults (make plots readable in slides)\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Matplotlib / Seaborn for plots\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Scikit-learn for modeling\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold, cross_validate\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, RocCurveDisplay, roc_auc_score, get_scorer\n",
        "\n",
        "# Make results reproducible\n",
        "RANDOM_STATE = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80c49c55",
      "metadata": {
        "id": "80c49c55"
      },
      "source": [
        "# Part A -- Load the dataset and explore shape, columns\n",
        "\n",
        "We'll load the Telco churn dataset from a hosted CSV. In a business setting this might come from a database / data warehouse.\n",
        "\n",
        "Each row is a customer, and the goal is to predict **`Churn`** (whether the customer left)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f6261c0",
      "metadata": {
        "id": "7f6261c0"
      },
      "outputs": [],
      "source": [
        "# ============================\n",
        "# Load the Telco churn dataset\n",
        "# ============================\n",
        "\n",
        "telco_url = \"https://raw.githubusercontent.com/plotly/datasets/master/telco-customer-churn-by-IBM.csv\"\n",
        "\n",
        "# Read the CSV into a pandas DataFrame (table)\n",
        "churn_df = pd.read_csv(telco_url)\n",
        "\n",
        "# Quick peek\n",
        "print(\"Shape:\", churn_df.shape)\n",
        "churn_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06060872",
      "metadata": {
        "id": "06060872"
      },
      "source": [
        "## 1) First sanity checks (structure, types, missing values)\n",
        "\n",
        "Before modeling, always ask:\n",
        "- What columns do we have?\n",
        "- Are there missing values?\n",
        "- Are numeric columns accidentally loaded as strings?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7ea8a32",
      "metadata": {
        "id": "c7ea8a32"
      },
      "outputs": [],
      "source": [
        "# Basic schema checks\n",
        "churn_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3375aa93",
      "metadata": {
        "id": "3375aa93"
      },
      "source": [
        "## 2) Minimal cleaning for modeling\n",
        "\n",
        "We'll do only the cleaning necessary to make the dataset usable for scikit-learn:\n",
        "\n",
        "1. Drop identifiers (e.g., `customerID`) — these usually do not help prediction.\n",
        "2. Convert `TotalCharges` to numeric (it often loads as an object/string).\n",
        "3. Deal with rows where conversion created missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "557891b5",
      "metadata": {
        "id": "557891b5"
      },
      "outputs": [],
      "source": [
        "# 1) Drop ID column if present\n",
        "if \"customerID\" in churn_df.columns:\n",
        "    churn_df = churn_df.drop(columns=[\"customerID\"])\n",
        "\n",
        "# 2) Convert TotalCharges to numeric (invalid parses become NaN)\n",
        "#    This is common when a column is \"mostly numeric\" but has blanks.\n",
        "if \"TotalCharges\" in churn_df.columns:\n",
        "    churn_df[\"TotalCharges\"] = pd.to_numeric(churn_df[\"TotalCharges\"], errors=\"coerce\")\n",
        "\n",
        "# Check what changed\n",
        "churn_df[\"TotalCharges\"].info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82ff9357",
      "metadata": {
        "id": "82ff9357"
      },
      "outputs": [],
      "source": [
        "# 3) Inspect rows where TotalCharges is missing after conversion\n",
        "rows_with_nulls = churn_df[\"TotalCharges\"].isna()\n",
        "\n",
        "print(\"Rows with TotalCharges missing:\", rows_with_nulls.sum())\n",
        "churn_df.loc[rows_with_nulls, [\"tenure\", \"MonthlyCharges\", \"TotalCharges\", \"Churn\"]].head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6374e7ce",
      "metadata": {
        "id": "6374e7ce"
      },
      "source": [
        "In this dataset, missing `TotalCharges` is typically associated with **tenure = 0** (new customers).\n",
        "For our purposes it is safe to drop these (they are very few, and we know they have not churned since they are still in their first month).\n",
        "\n",
        "> In a real project you would decide this more carefully (e.g., imputing, adding a missingness indicator, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b55c963",
      "metadata": {
        "id": "4b55c963"
      },
      "outputs": [],
      "source": [
        "# Drop rows with missing TotalCharges\n",
        "churn_df = churn_df.dropna(subset=[\"TotalCharges\"]).copy()\n",
        "\n",
        "print(\"Shape after dropping missing TotalCharges rows:\", churn_df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1693b7f3",
      "metadata": {
        "id": "1693b7f3"
      },
      "source": [
        "## 4) Separate target (`y`) from features (`X`)\n",
        "\n",
        "The models in sklearn take the data separated into features and labels/target, we will create:\n",
        "- `y` = the churn label (True/False)\n",
        "- `X` = all predictor columns\n",
        "\n",
        "We will also convert the object columns to category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a59fd50a",
      "metadata": {
        "id": "a59fd50a"
      },
      "outputs": [],
      "source": [
        "# Separate the target column\n",
        "y = churn_df[\"Churn\"].astype(str).str.strip().str.lower()  # normalize strings like \" Yes\"\n",
        "y = (y == \"yes\")                                          # convert to boolean (True = churn)\n",
        "\n",
        "# A human-friendly version for plots/tables (keeps notebooks readable)\n",
        "y_label = y.map({False: \"No churn\", True: \"Churn\"})\n",
        "\n",
        "# Drop target from features\n",
        "X = churn_df.drop(columns=[\"Churn\"])\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"Churn rate:\", y.mean())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the columns which should be categorical but are int (SeniorCitizen) or object to category\n",
        "# First convert Senior Citizen to boolean (True/False) for interpretability later\n",
        "X[\"SeniorCitizen\"] = (X[\"SeniorCitizen\"] == 1)\n",
        "\n",
        "# Now convert the object columns and SeniorCitizen to categorical\n",
        "object_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "X[[\"SeniorCitizen\"] + object_cols] = X[[\"SeniorCitizen\"] + object_cols].astype(\"category\")\n",
        "X.info()\n",
        "# Notice the size decreased from 1 MB to 300 KB"
      ],
      "metadata": {
        "id": "GziIptODxsIo"
      },
      "id": "GziIptODxsIo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b3c8dc77",
      "metadata": {
        "id": "b3c8dc77"
      },
      "source": [
        "# Part B — Prepare features for scikit-learn (dummy encoding)\n",
        "\n",
        "Scikit-learn’s decision trees can not handle categorical variables, and needs columns that are **numeric or boolean**.\n",
        "\n",
        "We'll use **one-hot encoding** (a.k.a. dummy variables) to convert categorical columns into 0/1 indicator columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c534107",
      "metadata": {
        "id": "8c534107"
      },
      "outputs": [],
      "source": [
        "# Convert object columns to 'category' dtype (helps keep track of what is categorical)\n",
        "# Note: If we just say X_encode = X, X_encode just points to X instead of making a new copy\n",
        "X_encoded = X.copy()\n",
        "\n",
        "# We will one-hot encode object columns.\n",
        "cat_cols = X_encoded.select_dtypes(include=[\"category\"]).columns.tolist()\n",
        "\n",
        "# One-hot encode categorical (object) columns as boolean.\n",
        "X_encoded = pd.get_dummies(X_encoded, columns=cat_cols)\n",
        "\n",
        "print(\"Encoded X shape:\", X_encoded.shape)\n",
        "X_encoded.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6c345a4",
      "metadata": {
        "id": "f6c345a4"
      },
      "source": [
        "# Part C — Train a few trees (different pruning strengths)\n",
        "\n",
        "Decision trees can overfit easily. To control the complexity, we use the Cost-complexity pruning parameter `ccp_alpha`.\n",
        "\n",
        "- **Small `ccp_alpha`** → less pruning → larger tree (more complex)\n",
        "- **Large `ccp_alpha`** → more pruning → smaller tree (simpler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27463d8f",
      "metadata": {
        "id": "27463d8f"
      },
      "outputs": [],
      "source": [
        "# Train two trees with different pruning strengths (alpha values)\n",
        "tree_alpha_high = 0.05   # more pruning (simpler tree)\n",
        "\n",
        "# impurity criterion is gini by default\n",
        "# we can optionally pass arguments to enable Pre-Pruning\n",
        "# e.g. max_depth, min_samples_split, min_samples_leaf, max_leaf_nodes,\n",
        "#      min_impurity_decrease\n",
        "tree_model_simple = tree.DecisionTreeClassifier(\n",
        "    random_state=RANDOM_STATE,\n",
        "    ccp_alpha=tree_alpha_high,\n",
        "    criterion=\"gini\"\n",
        ")\n",
        "\n",
        "# Note, there is a lot going on behind the scenes here fitting is a complex\n",
        "# process the first argument is a dataset of the predictors. the second is a\n",
        "# series of the target or y variable.\n",
        "tree_model_simple.fit(X_encoded, y)\n",
        "\n",
        "# Visualize the tree\n",
        "fig = plt.figure(figsize=(7,7))\n",
        "_ = tree.plot_tree(tree_model_simple,\n",
        "                   feature_names=X_encoded.columns.to_list(), # make sure the feature names are in output\n",
        "                   filled=True) # filled true color codes by the class. shading indicates proportion or quality of split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we build a slightly more complex tree by reducing the complexity penalty\n",
        "tree_alpha_low  = 0.0   # less pruning (more complex tree)\n",
        "\n",
        "tree_model_complex = tree.DecisionTreeClassifier(\n",
        "    random_state=RANDOM_STATE,\n",
        "    ccp_alpha=tree_alpha_low,\n",
        "    max_leaf_nodes=10,\n",
        "    criterion=\"gini\"\n",
        ")\n",
        "tree_model_complex.fit(X_encoded, y)\n",
        "fig = plt.figure(figsize=(7,7))\n",
        "_ = tree.plot_tree(tree_model_complex,\n",
        "                   feature_names=X_encoded.columns.to_list(), # make sure the feature names are in output\n",
        "                   filled=True) # filled true color codes by the class. shading indicates proportion or quality of split\n"
      ],
      "metadata": {
        "id": "oPgAtg9l8XYP"
      },
      "id": "oPgAtg9l8XYP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part D -- Confusion Matrix and Classification report"
      ],
      "metadata": {
        "id": "w3HQqeDTbKPJ"
      },
      "id": "w3HQqeDTbKPJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix"
      ],
      "metadata": {
        "id": "ynnhg2AqbiZn"
      },
      "id": "ynnhg2AqbiZn"
    },
    {
      "cell_type": "code",
      "source": [
        "# First produce the predictions from the model\n",
        "model_preds = tree_model_simple.predict(X_encoded)\n",
        "model_cm = confusion_matrix(y_true=y, y_pred = model_preds)\n",
        "model_cm"
      ],
      "metadata": {
        "id": "KM0GRts3bIq_"
      },
      "id": "KM0GRts3bIq_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the confusion matrix in a prettier format by converting it to a DataFrame\n",
        "class_names = y.unique()\n",
        "cm_df = pd.DataFrame(model_cm, index = class_names, columns = class_names)\n",
        "display(cm_df)"
      ],
      "metadata": {
        "id": "64yHR6lfb05b"
      },
      "id": "64yHR6lfb05b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_estimator(tree_model_simple, X_encoded, y)"
      ],
      "metadata": {
        "id": "UL8SwkfRivr5"
      },
      "id": "UL8SwkfRivr5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification Report"
      ],
      "metadata": {
        "id": "Dc__-o01dSGn"
      },
      "id": "Dc__-o01dSGn"
    },
    {
      "cell_type": "code",
      "source": [
        "# Produce the Classification report which has Precision, Recall, Accuracy, F-score\n",
        "model_cr = classification_report(y, model_preds)\n",
        "print(model_cr)"
      ],
      "metadata": {
        "id": "ne1KjerhcD5r"
      },
      "id": "ne1KjerhcD5r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Same thing for tree_model_complex\n",
        "# Predict Labels\n",
        "model_preds = tree_model_complex.predict(X_encoded)\n",
        "# Compute Confusion Matrix by passing true labels, and predictions\n",
        "model_cm = confusion_matrix(y_true=y, y_pred = model_preds)\n",
        "class_names = y.unique()\n",
        "cm_df = pd.DataFrame(model_cm, index = class_names, columns = class_names)\n",
        "display(cm_df)\n",
        "# Confusion Matrix\n",
        "model_cr = classification_report(y, model_preds)\n",
        "print(model_cr)"
      ],
      "metadata": {
        "id": "7S3UzOoPcfkJ"
      },
      "id": "7S3UzOoPcfkJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part E — ROC curve and AUC\n",
        "\n",
        "We will use `RocCurveDisplay` from `sklearn.metrics` to produce an ROC curve. This function extracts the class probabilities, and adjusts the threshold of a threshold based rule to produce the TPR vs. FPR plot and also computes Area Under Curve (AUC)"
      ],
      "metadata": {
        "id": "NSgvIVK-da97"
      },
      "id": "NSgvIVK-da97"
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us first see how we can extract the predictions from the Decision Tree we fitted\n",
        "model_preds_prob_sample = tree_model_complex.predict_proba(X_encoded.iloc[0:5,:])\n",
        "model_preds_sample = tree_model_complex.predict(X_encoded.iloc[0:5,:])\n",
        "print(model_preds_prob_sample)\n",
        "print(model_preds_sample)"
      ],
      "metadata": {
        "id": "zV2I1G0ld46a"
      },
      "id": "zV2I1G0ld46a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the ROC curve\n",
        "roc_display = RocCurveDisplay.from_estimator(tree_model_complex, X_encoded, y, name='Decision Tree')\n",
        "# Print the AUC score\n",
        "auc_score = roc_display.roc_auc\n",
        "print(f'AUC for the Decision Tree Classifier: {auc_score:.3f}')"
      ],
      "metadata": {
        "id": "zlIzC9U3d0mJ"
      },
      "id": "zlIzC9U3d0mJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Can also get auc score directly by passing true target values, probabilities (or scores)\n",
        "auc_score = roc_auc_score(y, tree_model_complex.predict_proba(X_encoded)[:,1])\n",
        "auc_score"
      ],
      "metadata": {
        "id": "pSM7WTwPbZrY"
      },
      "id": "pSM7WTwPbZrY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0a5d4d9d",
      "metadata": {
        "id": "0a5d4d9d"
      },
      "source": [
        "# Part F — Train/Test split -- Model evaluation\n",
        "\n",
        "We care about performance on **future unseen customers** (population/generalization), not performance on the training sample.\n",
        "\n",
        "If we evaluate on the same data we trained on, performance is usually **too optimistic**.\n",
        "\n",
        "We will:\n",
        "1. Split our data into train and test sets\n",
        "2. Train a simple and a complex tree model on the train split\n",
        "3. Compute the classification metrics on test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85b7e1c8",
      "metadata": {
        "id": "85b7e1c8"
      },
      "outputs": [],
      "source": [
        "# Train/test split\n",
        "# Saving 30% of data for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_encoded, y,\n",
        "    test_size=0.30,\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=y  # keep class balance similar in train and test\n",
        ")\n",
        "\n",
        "print(\"Train shape:\", X_train.shape, \"| Test shape:\", X_test.shape)\n",
        "# The following command shows that the splitting preserved class balance across\n",
        "# test and train splits\n",
        "print(\"Train churn rate:\", y_train.mean(), \"| Test churn rate:\", y_test.mean())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the simple and complex models\n",
        "tree_model_simple.fit(X_train, y_train)\n",
        "tree_model_complex.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "wsBxfKCjf3b7"
      },
      "id": "wsBxfKCjf3b7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For the simple model produce the Classification Report on train and test data\n",
        "print(classification_report(y_train, tree_model_simple.predict(X_train)))\n",
        "print(classification_report(y_test, tree_model_simple.predict(X_test)))"
      ],
      "metadata": {
        "id": "V2YgJph6gI5H"
      },
      "id": "V2YgJph6gI5H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For the simple model produce the Classification Report on train and test data\n",
        "\n",
        "# Note: You should not report classification metrics on training data, we are doing it here just to contrast with metrics on test split\n",
        "print(classification_report(y_train, tree_model_complex.predict(X_train)))\n",
        "# Note: This is what you should actually look at to estimate the performance you should expect on unseen data\n",
        "print(classification_report(y_test, tree_model_complex.predict(X_test)))"
      ],
      "metadata": {
        "id": "ez0vT3KUghKO"
      },
      "id": "ez0vT3KUghKO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us check ROC, AUC on the test set as well\n",
        "roc_display = RocCurveDisplay.from_estimator(tree_model_complex, X_test, y_test, name='Decision Tree')\n",
        "# Print the AUC score\n",
        "auc_score = roc_display.roc_auc\n",
        "print(f'AUC for the Decision Tree Classifier: {auc_score:.3f}')"
      ],
      "metadata": {
        "id": "oOMQZCi_jvYm"
      },
      "id": "oOMQZCi_jvYm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part G — Model Selection using Cross-Validation\n",
        "\n",
        "Model Selection means deciding how complex a Decision Tree is appropriate to fit to the data set we have. The steps are as follows:\n",
        "\n",
        "1. First do a train/test split, say 80/20. Keep the test set apart. Make sure class balances is maintained by doing this split (i.e. fraction of y=Yes in train and test are the same). For reproducibility, explicitly pass the random number seed.\n",
        "2. Split the train set into K folds of (roughly equal) sizes. Again make sure this is done while stratifying on the target. For reproducibility, explicitly pass the random number seed.\n",
        "3. For each model complexity parameter (e.g. number of leaves),\n",
        "    1. For each i in (1,...,K):\n",
        "        - train the Decision Tree on training set with fold i excluded\n",
        "        - compute the accuracy of this model on fold i. This is an estimate of the generalization performance (error on unseen test data) for this model complexity.\n",
        "        - save this accuracy metric\n",
        "    2. Compute summary of the K accuracy measurements (mean, standard deviation)\n",
        "4. Based on the cross-validation performance, choose the **model class** which is estimated to generalize the best\n",
        "5. Train the model again, this time on the entire training set.\n",
        "6. Compute the performance on the hold-out test set (from step 1). This is the estimate of your model's performance on the population distribution."
      ],
      "metadata": {
        "id": "D46K4Ko1hE2p"
      },
      "id": "D46K4Ko1hE2p"
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up a random K-fold and stratified K-fold samplers\n",
        "\n",
        "num_folds = 3\n",
        "\n",
        "print(\"Stratified K-Fold\")\n",
        "print(\"-\"*20)\n",
        "\n",
        "# Define how we will create the folds (this is where we can pass the seed for random generator\n",
        "cv_strategy = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=RANDOM_STATE)\n",
        "# Iterate through the folds and report fraction yes\n",
        "for i, (train_indices, test_indices) in enumerate(cv_strategy.split(X_train, y_train)):\n",
        "    print(f\"Fold {i}:\")\n",
        "    print(f\"  Test indices = {test_indices}\")\n",
        "    print(f\"  Fraction Yes = {y_train.iloc[test_indices].mean()}\")\n",
        "\n",
        "cv_strategy = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=RANDOM_STATE)\n",
        "indices = cv_strategy.get_n_splits(X_train, y_train)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"Random K-Fold\")\n",
        "print(\"-\"*20)\n",
        "\n",
        "# Define how we will create the folds (this is where we can pass the seed for random generator\n",
        "cv_strategy = KFold(n_splits=num_folds, shuffle=True, random_state=RANDOM_STATE)\n",
        "# Iterate through the folds and report fraction yes\n",
        "for i, (train_indices, test_indices) in enumerate(cv_strategy.split(X_train, y_train)):\n",
        "    print(f\"Fold {i}:\")\n",
        "    print(f\"  Test indices = {test_indices}\")\n",
        "    print(f\"  Fraction Yes = {y_train.iloc[test_indices].mean()}\")"
      ],
      "metadata": {
        "id": "1dMrY7lWT42d"
      },
      "id": "1dMrY7lWT42d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do cross-validation\n",
        "# ====================\n",
        "\n",
        "# List of -log_2 ccp_alphas we will try (ccp_alpha will be: 1/4, 1/16, 1/64, ...)\n",
        "# We can also use cost_complexity_pruning_path on training data to get a potential list of alphas\n",
        "minus_log2_alpha_list = np.arange(2,21,2)\n",
        "\n",
        "# Number of folds for k-fold cross validation\n",
        "num_folds = 10\n",
        "\n",
        "# Define how we will create the folds (this is where we can pass the seed for random generator)\n",
        "cv_strategy = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "# This dataframe will store our results\n",
        "cv_results_df = pd.DataFrame(columns=['minus_log2_alpha', 'mean', 'stddev', 'test_accuracy', 'test_auc'])\n",
        "\n",
        "# Iterate over ccp_alpha parameter\n",
        "for i in minus_log2_alpha_list:\n",
        "    # Define the Tree classifier object\n",
        "    tree_model = tree.DecisionTreeClassifier(random_state = RANDOM_STATE, ccp_alpha = 2.0**(-i))\n",
        "\n",
        "    # Do the cross-validation runs and collate scores for the num_folds runs\n",
        "    # There is a lot that is happening in this function!!\n",
        "    result_list = cross_val_score(tree_model, X_train, y_train, cv = cv_strategy, scoring = 'accuracy')\n",
        "\n",
        "    # ============================================================\n",
        "    # Fit the model with this ccp_alpha on the full training data\n",
        "    # In real workflows you will NOT do this for every alpha, but for the alpha\n",
        "    # corresponding to the model you select based on Cross-validation!\n",
        "    # We are doing this here only for illustration\n",
        "    tree_model.fit(X_train, y_train)\n",
        "\n",
        "    # ============================================================\n",
        "    # Find accuracy on the hold out test set\n",
        "    # NOTE: We are peeking at the test set across alphas for illustration only; do not do this in real workflows.\n",
        "    # In real workflows you will only do this at the end for the one alpha you\n",
        "    # select as your chosen model complexity parameter!\n",
        "    test_score = tree_model.score(X_test, y_test)\n",
        "\n",
        "    # ============================================================\n",
        "    # Let us also look at the auc score on test data\n",
        "    # In real workflows you will only do this at the end for the one alpha you\n",
        "    # select as your chosen model complexity parameter!\n",
        "    auc_score = roc_auc_score(y_test, tree_model.predict_proba(X_test)[:,1])\n",
        "\n",
        "    # Add this row to the data frame\n",
        "    new_data = {'minus_log2_alpha': i, 'mean': result_list.mean() ,\n",
        "                'stddev' : result_list.std(ddof=1) , 'test_accuracy' : test_score,\n",
        "                'test_auc' : auc_score}\n",
        "    cv_results_df.loc[len(cv_results_df)] = new_data"
      ],
      "metadata": {
        "id": "Y5T0rf5Wj6TZ"
      },
      "id": "Y5T0rf5Wj6TZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot results\n",
        "# ===================\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7, 5))\n",
        "\n",
        "# Produce a plot of mean cross-validation accuracy for each model class\n",
        "ax.plot(cv_results_df['minus_log2_alpha'], cv_results_df['mean'], marker = 'o', label = 'Mean CV accuracy')\n",
        "\n",
        "# Overlay \"Error bars\" using standard deviation of CV accuracy on the folds\n",
        "ax.fill_between(cv_results_df['minus_log2_alpha'],\n",
        "                 cv_results_df['mean'] - cv_results_df['stddev'],\n",
        "                 cv_results_df['mean'] + cv_results_df['stddev'],\n",
        "                 alpha=0.2,\n",
        "                 label=\"CV ±1 SD\")\n",
        "\n",
        "# Overlay Test Accuracy (on held out test data)\n",
        "ax.plot(cv_results_df['minus_log2_alpha'], cv_results_df['test_accuracy'], marker = 'o', linestyle ='--' , label = 'Test accuracy')\n",
        "# ticks and labels\n",
        "ax.set_xticks(minus_log2_alpha_list)\n",
        "ax.set_xlabel(r'$-\\log_2 \\alpha$')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.legend()\n",
        "\n",
        "# Add plot for AUC on test data using secondary axis\n",
        "color2 = 'tab:red'\n",
        "ax2 = ax.twinx()\n",
        "ax2.plot(cv_results_df['minus_log2_alpha'], cv_results_df['test_auc'], marker = 'o', color = color2, label = 'AUC')\n",
        "ax2.set_ylabel('AUC', color = color2)\n",
        "ax2.tick_params(axis='y', labelcolor=color2)\n",
        "\n",
        "plt.show()\n",
        "plt.tight_layout()\n"
      ],
      "metadata": {
        "id": "c-0ibE84f9OM"
      },
      "id": "c-0ibE84f9OM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUDO: Experiment with this block\n",
        "# The cross_validate function gives more flexibility in using different scoring\n",
        "# rules to perform cross validation\n",
        "\n",
        "num_folds = 10\n",
        "\n",
        "# 1. Pick ONE scoring rule (string) for the sweep:\n",
        "scoring_rule = \"roc_auc\"\n",
        "# scoring_rule = \"accuracy\"\n",
        "# scoring_rule = \"balanced_accuracy\"\n",
        "# scoring_rule = \"precision\"\n",
        "# scoring_rule = \"recall\"\n",
        "# scoring_rule = \"f1\"\n",
        "# scoring_rule = \"f1_macro\"\n",
        "# scoring_rule = \"average_precision\"  # PR-AUC\n",
        "\n",
        "# You can also see MULTIPLE metrics in one CV call and then select one to plot or use.\n",
        "# Uncomment this and set metric_to_plot accordingly.\n",
        "# scoring = {\n",
        "#     \"acc\": \"accuracy\",\n",
        "#     \"bal_acc\": \"balanced_accuracy\",\n",
        "#     \"prec\": \"precision\",\n",
        "#     \"rec\": \"recall\",\n",
        "#     \"f1\": \"f1\",\n",
        "#     \"auc\": \"roc_auc\",\n",
        "#     \"ap\": \"average_precision\",\n",
        "# }\n",
        "# metric_to_plot = \"auc\"   # must be one of the keys above\n",
        "\n",
        "cv = StratifiedKFold(n_splits = num_folds, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "# A scorer object lets you evaluate the *test set* using the exact same scoring rule string.\n",
        "# (Works for metrics like roc_auc that need predict_proba/decision_function too.)\n",
        "scorer = get_scorer(scoring_rule)\n",
        "\n",
        "# List of -log_2 ccp_alphas we will try (ccp_alpha will be: 1/4, 1/16, 1/64, ...)\n",
        "# We can also use cost_complexity_pruning_path on training data to get a potential list of alphas\n",
        "minus_log2_alpha_list = np.arange(2,21,2)\n",
        "alphas = 0.5**minus_log2_alpha_list\n",
        "\n",
        "mean_cv_scores = []\n",
        "std_cv_scores  = []\n",
        "test_scores    = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    # Create a fresh estimator for this alpha\n",
        "    tree_model = tree.DecisionTreeClassifier(\n",
        "        random_state=RANDOM_STATE,\n",
        "        ccp_alpha=float(alpha),\n",
        "        # max_leaf_nodes=10,  # keep if you used it elsewhere; otherwise remove for \"pure\" pruning\n",
        "    )\n",
        "\n",
        "    # --- Cross-validated estimate (replaces cross_val_score) ---\n",
        "    cv_out = cross_validate(\n",
        "        tree_model,\n",
        "        X_train,\n",
        "        y_train,\n",
        "        cv=cv,\n",
        "        scoring=scoring_rule,        # or scoring=scoring for multiple metrics\n",
        "        return_train_score=False\n",
        "    )\n",
        "\n",
        "    fold_scores = cv_out[\"test_score\"]  # for multi-metric: cv_out[\"test_auc\"], etc.\n",
        "    mean_cv_scores.append(np.mean(fold_scores))\n",
        "    std_cv_scores.append(np.std(fold_scores, ddof=1))\n",
        "\n",
        "    # --- Test-set score for THIS alpha ---\n",
        "     # NOTE: This \"peeks\" at test across alphas. We are doing this for illustration only!\n",
        "    tree_model.fit(X_train, y_train)\n",
        "    test_scores.append(scorer(tree_model, X_test, y_test))\n",
        "\n",
        "mean_cv_scores = np.asarray(mean_cv_scores)\n",
        "std_cv_scores  = np.asarray(std_cv_scores)\n",
        "test_scores    = np.asarray(test_scores)\n",
        "\n",
        "# Pick alpha by CV (max metric)\n",
        "best_idx = int(np.argmax(mean_cv_scores))\n",
        "best_alpha = float(alphas[best_idx])\n",
        "\n",
        "print(f\"Best alpha by CV ({scoring_rule}): {best_alpha:g}\")\n",
        "print(f\"  CV mean = {mean_cv_scores[best_idx]:.4f}\")\n",
        "print(f\"  Test    = {test_scores[best_idx]:.4f}  (for this alpha)\")\n"
      ],
      "metadata": {
        "id": "ee9l3bRHpXKT"
      },
      "id": "ee9l3bRHpXKT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- Plot CV vs Test across alphas --------------------\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.plot(alphas, mean_cv_scores, marker=\"o\", label=f\"CV mean ({scoring_rule})\")\n",
        "ax.fill_between(\n",
        "    alphas,\n",
        "    mean_cv_scores - std_cv_scores,\n",
        "    mean_cv_scores + std_cv_scores,\n",
        "    alpha=0.2,\n",
        "    label=\"CV ±1 SD\"\n",
        ")\n",
        "ax.plot(alphas, test_scores, marker=\"o\", linestyle=\"--\", label=f\"Test ({scoring_rule})\")\n",
        "\n",
        "# Log x-axis only if all alphas are > 0 (log(0) not allowed)\n",
        "if np.all(alphas > 0):\n",
        "    ax.set_xscale(\"log\")\n",
        "\n",
        "ax.set_xlabel(\"ccp_alpha\")\n",
        "ax.set_ylabel(scoring_rule)\n",
        "ax.set_title(f\"Decision Tree pruning sweep: {scoring_rule}\")\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n",
        "# -------------------- Plot ROC curve on TEST for best alpha --------------------\n",
        "final_model = tree.DecisionTreeClassifier(random_state=0, ccp_alpha=best_alpha)\n",
        "final_model.fit(X_train, y_train)\n",
        "RocCurveDisplay.from_estimator(final_model, X_test, y_test)\n",
        "plt.title(f\"Test ROC curve (best alpha = {best_alpha:g})\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jmkVXc_ItTsE"
      },
      "id": "jmkVXc_ItTsE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "461c2b77",
      "metadata": {
        "id": "461c2b77"
      },
      "source": [
        "# Summary / takeaway\n",
        "\n",
        "- Decision trees can fit complex patterns, but they can also **overfit**.\n",
        "- Use a **validation set / cross-validation** to choose model complexity properly.\n",
        "- Next week: Compare a single tree to ensembles (Random Forest, Gradient Boosting)."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bkrVuzi3ge4t"
      },
      "id": "bkrVuzi3ge4t",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}